{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from numpy import where\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "from keras.layers import Dense, Dropout, LeakyReLU\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.utils import to_categorical\n",
    "import itertools\n",
    "\n",
    "%cd C:\\\\Users\\\\Ben\\\\Desktop\\\\UNH Classes\\\\Data 903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data\n",
    "from  sklearn.datasets import make_classification as makeclass\n",
    "X,y = makeclass(n_samples=10000, n_features=15, n_informative=10, n_redundant=0, \n",
    "          n_repeated=0, n_classes=6, n_clusters_per_class=3, weights=None, flip_y=0.01, \n",
    "          class_sep=0.7, hypercube=False, shift=2, scale=1.0, shuffle=True, random_state=682502)\n",
    "\n",
    "y = to_categorical(y)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 5000\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Part 1 for Sigmoid and ReLU #####\n",
    "#######################################\n",
    "\n",
    "# Number of epochs (only altered while testing)\n",
    "EP = 100\n",
    "\n",
    "# Set hyperparamaters for non-leaky activations\n",
    "act = ['sigmoid', 'relu']\n",
    "nod = [10, 20, 50]\n",
    "bat = [8, 16, 32]\n",
    "lay = [1,2]\n",
    "\n",
    "#function for permutations\n",
    "def hyper_paramters(act, nod, bat, lay):\n",
    "    \n",
    "    lists = [act, nod, bat, lay]\n",
    "    \n",
    "    perm = list(itertools.product(*lists))\n",
    "    \n",
    "    return perm\n",
    "\n",
    "#execution of function\n",
    "perm = hyper_paramters(act,nod,bat,lay)\n",
    "\n",
    "\n",
    "#length of all combinations\n",
    "len(perm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid and ReLU model function\n",
    "def RunNN(act,nod,bat,lay):\n",
    "    print(\"\")\n",
    "    print(\"Working on model configuration with activation: \" + str(act) + \", nodes: \" + str(nod)+ \", batches: \" + str(bat) +\n",
    "          \", and layers: \" + str(lay))\n",
    "    print(str(len(perm)-i) + \" configurations left to try.\")\n",
    "    print(\"\")\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(nod, input_dim=15, activation=act))\n",
    "    \n",
    "    model.add(Dense(nod, activation=act))\n",
    "    \n",
    "    if lay == 2:\n",
    "        model.add(Dense(nod, activation=act))\n",
    "        \n",
    "        model.add(Dense(6, activation='softmax'))\n",
    "    \n",
    "\n",
    "\n",
    "        # compile model\n",
    "        opt = RMSprop(lr=0.01, rho=0.9)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "        # fit model\n",
    "        history[i]= model.fit(trainX, trainy, validation_data=(testX, testy), epochs=EP, verbose=1, batch_size=bat)\n",
    "\n",
    "\n",
    "        configs.append(str(act) + \", \" + str(nod) + \", \" + str(bat) + \", \"+ str(lay))    \n",
    "        \n",
    "              \n",
    "    else:\n",
    "    \n",
    "        model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "        # compile model\n",
    "        opt = RMSprop(lr=0.01, rho=0.9)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "        # fit model\n",
    "        history[i]= model.fit(trainX, trainy, validation_data=(testX, testy), epochs=EP, verbose=1, batch_size=bat)\n",
    "\n",
    "\n",
    "        configs.append(str(act) + \", \" + str(nod) + \", \" + str(bat) + \", \"+ str(lay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create objects for storing configurations and model performance\n",
    "configs = []\n",
    "history = {}\n",
    "\n",
    "# Run the sigmoid/relu model by entering the combinations through the model function\n",
    "for i in range(0, len(perm)):\n",
    "    RunNN(perm[i][0],perm[i][1],perm[i][2],perm[i][3])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Transform Sigmoid / ReLU results and save output ###\n",
    "########################################################\n",
    "\n",
    "# Create rows by repeating the configuration settings to match the number of epochs\n",
    "\n",
    "CF = pd.DataFrame(configs)\n",
    "newCF = pd.DataFrame(np.repeat(CF.values,EP,axis=0))\n",
    "newCF.columns = ['config']\n",
    "newCF = newCF['config'].str.split(',', 3, expand=True)\n",
    "newCF.columns = ['act','nod','bat','lay']\n",
    "newCF\n",
    "\n",
    "# Loop through history dict to create a DF with epoch number and acc score\n",
    "DF = []\n",
    "for i in range(0, len(history)):\n",
    "    epoch_res = pd.DataFrame(history[i].history)\n",
    "    epoch_res['epoch'] = epoch_res.index+1\n",
    "    epoch_res = epoch_res[['epoch','acc']]\n",
    "    DF.append(epoch_res)\n",
    "\n",
    "# Combine epoch configurations with their respective epochs and acc scores \n",
    "\n",
    "DF2 = pd.concat(DF).reset_index(drop=True)\n",
    "DF3 = DF2[['epoch', 'acc']]\n",
    "DF4 = pd.merge(newCF,DF3, left_index=True, right_index=True)\n",
    "\n",
    "DF5 = pd.pivot_table(DF4, columns='epoch', values='acc',index =['act','nod','bat','lay'])\n",
    "\n",
    "DF5.to_csv('nonleaky.csv')\n",
    "DF5.to_excel('nonleaky.xlsx')\n",
    "DF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Part 1 for Leaky ReLU ###########\n",
    "#######################################\n",
    "\n",
    "# Number of epochs (only altered while testing)\n",
    "EP = 100\n",
    "\n",
    "# Set hyperparamaters for leaky activation\n",
    "# act = ['sigmoid', 'relu']\n",
    "nod = [10, 20, 50]\n",
    "bat = [8, 16, 32]\n",
    "lay = [1,2]\n",
    "\n",
    "#function for permutations\n",
    "def hyper_leaky(nod, bat, lay):\n",
    "    \n",
    "    lists = [nod, bat, lay]\n",
    "    \n",
    "    perm = list(itertools.product(*lists))\n",
    "    \n",
    "    return perm\n",
    "\n",
    "#execution of function\n",
    "perm = hyper_leaky(nod,bat,lay)\n",
    "\n",
    "\n",
    "#length of all combinations\n",
    "len(perm)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaky ReLU model function\n",
    "def RunNNLeaky(nod,bat,lay):\n",
    "    print(\"\")\n",
    "    print(\"Working on model configuration with nodes: \" + str(nod)+ \", batches: \" + str(bat) + \", and layers: \" + str(lay))\n",
    "    print(str(len(perm)-i) + \" configurations left to try.\")\n",
    "    print(\"\")\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(nod, input_dim=15))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(nod))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    if lay == 2:\n",
    "        model.add(Dense(nod))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        \n",
    "        model.add(Dense(6, activation='softmax'))\n",
    "    \n",
    "\n",
    "\n",
    "        # compile model\n",
    "        opt = RMSprop(lr=0.01, rho=0.9)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "        # fit model\n",
    "        history[i]= model.fit(trainX, trainy, validation_data=(testX, testy), epochs=EP, verbose=1, batch_size=bat)\n",
    "\n",
    "\n",
    "        configs.append(str(nod) + \", \" + str(bat) + \", \"+ str(lay))    \n",
    "        \n",
    "              \n",
    "    else:\n",
    "    \n",
    "        model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "        # compile model\n",
    "        opt = RMSprop(lr=0.01, rho=0.9)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "        # fit model\n",
    "        history[i]= model.fit(trainX, trainy, validation_data=(testX, testy), epochs=EP, verbose=1, batch_size=bat)\n",
    "\n",
    "\n",
    "        configs.append(str(nod) + \", \" + str(bat) + \", \"+ str(lay))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create objects for storing configurations and model performance\n",
    "configs = []\n",
    "history = {}\n",
    "\n",
    "# Run the model by entering the combinations through the model function\n",
    "for i in range(0, len(perm)):\n",
    "    RunNNLeaky(perm[i][0],perm[i][1],perm[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transform Leaky ReLU results and save output ###\n",
    "####################################################\n",
    "\n",
    "# Create rows by repeating the configuration settings to match the number of epochs\n",
    "CF = pd.DataFrame(configs)\n",
    "newCF = pd.DataFrame(np.repeat(CF.values,EP,axis=0))\n",
    "newCF.columns = ['config']\n",
    "newCF = newCF['config'].str.split(',', 3, expand=True)\n",
    "newCF.columns = ['nod','bat','lay']\n",
    "newCF\n",
    "\n",
    "\n",
    "# Loop through history dict to create a DF with epoch number and acc score\n",
    "DF = []\n",
    "for i in range(0, len(history)):\n",
    "    epoch_res = pd.DataFrame(history[i].history)\n",
    "    epoch_res['epoch'] = epoch_res.index+1\n",
    "    epoch_res = epoch_res[['epoch','acc']]\n",
    "    DF.append(epoch_res)\n",
    "\n",
    "# Combine epoch configurations with their respective epochs and acc scores \n",
    "\n",
    "DF2 = pd.concat(DF).reset_index(drop=True)\n",
    "DF3 = DF2[['epoch', 'acc']]\n",
    "DF4 = pd.merge(newCF,DF3, left_index=True, right_index=True)\n",
    "DF4['act'] = 'leaky'\n",
    "DF4 = DF4[['act', 'nod', 'bat', 'lay', 'epoch', 'acc']]\n",
    "\n",
    "DF5 = pd.pivot_table(DF4, columns='epoch', values='acc',index =['act','nod','bat','lay'])\n",
    "\n",
    "# DF5.to_csv('leaky.csv')\n",
    "# DF5.to_excel('leaky.xlsx')\n",
    "\n",
    "DF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Part 2 ##########################\n",
    "#######################################\n",
    "\n",
    "# Number of epochs (only altered while testing)\n",
    "EP = 100\n",
    "\n",
    "# Set hyperparamaters for leaky activation\n",
    "\n",
    "opt = ['sgd', 'rmsprop', 'adam']\n",
    "wgt = ['glorot_uniform', 'glorot_normal','he_uniform', 'he_normal']\n",
    "drp = [0.2, 0.4, 0.5]\n",
    "\n",
    "#function for permutations\n",
    "def hyper_2(opt, wgt, drp):\n",
    "    \n",
    "    lists = [opt, wgt, drp]\n",
    "    \n",
    "    perm = list(itertools.product(*lists))\n",
    "    \n",
    "    return perm\n",
    "\n",
    "#execution of function\n",
    "perm = hyper_2(opt, wgt, drp)\n",
    "\n",
    "\n",
    "#length of all combinations\n",
    "len(perm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunNN2(opt,wgt,drp):\n",
    "    print(\"\")\n",
    "    print(\"Working on model configuration with optimization: \" + str(opt)+ \", weights: \" + str(wgt) + \", and dropout: \" + str(drp))\n",
    "    print(str(len(perm)-i) + \" configurations left to try.\")\n",
    "    print(\"\")\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=15, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(drp))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "    # compile model\n",
    "    if opt == 'sgd':\n",
    "        optz = SGD(lr=0.01)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optz, metrics=['accuracy'])\n",
    "\n",
    "        # fit model\n",
    "        history[i]= model.fit(trainX, trainy, validation_data=(testX, testy), epochs=EP, verbose=1, batch_size=32)\n",
    "\n",
    "\n",
    "        configs.append(str(opt) + \", \" + str(wgt) + \", \"+ str(drp))\n",
    "        \n",
    "        \n",
    "    elif opt == 'rmsprop':\n",
    "        optz = RMSprop(lr=0.01, rho=0.9)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optz, metrics=['accuracy'])\n",
    "\n",
    "        # fit model\n",
    "        history[i]= model.fit(trainX, trainy, validation_data=(testX, testy), epochs=EP, verbose=1, batch_size=32)\n",
    "\n",
    "\n",
    "        configs.append(str(opt) + \", \" + str(wgt) + \", \"+ str(drp))    \n",
    "\n",
    "    else:\n",
    "        optz = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optz, metrics=['accuracy'])\n",
    "\n",
    "        # fit model\n",
    "        history[i]= model.fit(trainX, trainy, validation_data=(testX, testy), epochs=EP, verbose=1, batch_size=32)\n",
    "\n",
    "\n",
    "        configs.append(str(opt) + \", \" + str(wgt) + \", \"+ str(drp))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create objects for storing configurations and model performance\n",
    "configs = []\n",
    "history = {}\n",
    "\n",
    "# Run the model by entering the combinations through the model function\n",
    "for i in range(0, len(perm)):\n",
    "    RunNN2(perm[i][0],perm[i][1],perm[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create rows by repeating the configuration settings to match the number of epochs\n",
    "CF = pd.DataFrame(configs)\n",
    "newCF = pd.DataFrame(np.repeat(CF.values,EP,axis=0))\n",
    "newCF.columns = ['config']\n",
    "newCF = newCF['config'].str.split(',', 3, expand=True)\n",
    "newCF.columns = ['opt','wgt','drp']\n",
    "newCF\n",
    "\n",
    "\n",
    "# Loop through history dict to create a DF with epoch number and acc score\n",
    "DF = []\n",
    "for i in range(0, len(history)):\n",
    "    epoch_res = pd.DataFrame(history[i].history)\n",
    "    epoch_res['epoch'] = epoch_res.index+1\n",
    "    epoch_res = epoch_res[['epoch','acc']]\n",
    "    DF.append(epoch_res)\n",
    "\n",
    "# Combine epoch configurations with their respective epochs and acc scores \n",
    "\n",
    "DF2 = pd.concat(DF).reset_index(drop=True)\n",
    "DF3 = DF2[['epoch', 'acc']]\n",
    "DF4 = pd.merge(newCF,DF3, left_index=True, right_index=True)\n",
    "DF4['act'] = 'leaky'\n",
    "DF4 = DF4[['opt','wgt','drp', 'epoch', 'acc']]\n",
    "\n",
    "DF5 = pd.pivot_table(DF4, columns='epoch', values='acc',index =['opt','wgt','drp'])\n",
    "\n",
    "DF5.to_csv('part2.csv')\n",
    "DF5.to_excel('part2.xlsx')\n",
    "\n",
    "DF5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
